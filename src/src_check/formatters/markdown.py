"""Markdown formatter for report generation."""

from collections import defaultdict
from datetime import datetime
from typing import Dict, List

from src_check.formatters import BaseFormatter
from src_check.models.check_result import CheckResult, Severity
from src_check.models.simple_kpi_score import KpiScore


class MarkdownFormatter(BaseFormatter):
    """Formatter for Markdown output."""

    def format(self, results: Dict[str, List[CheckResult]], kpi: KpiScore) -> str:
        """Format results as Markdown.

        Args:
            results: Dictionary mapping file paths to their check results
            kpi: Overall KPI score

        Returns:
            Markdown formatted string
        """
        output = []

        # Header
        output.append("# SRC-CHECK Analysis Report")
        output.append(
            f"\n*Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
        )

        # Executive Summary
        output.append("## Executive Summary")
        output.append(self._format_kpi_summary(kpi))
        output.append("")

        # Statistics
        output.append("## Statistics")
        output.append(self._format_statistics(results))
        output.append("")

        # Issues by Severity
        output.append("## Issues by Severity")
        output.append(self._format_issues_by_severity(results))
        output.append("")

        # Detailed Findings
        if results:
            output.append("## Detailed Findings")
            output.append("")

            for file_path, file_results in sorted(results.items()):
                if file_results:
                    output.append(f"### ğŸ“„ `{file_path}`")
                    output.append("")

                    # Create table for this file
                    output.append("| Severity | Rule | Message | Location |")
                    output.append("|----------|------|---------|----------|")

                    # Sort by severity
                    sorted_results = sorted(
                        file_results,
                        key=lambda r: [
                            Severity.CRITICAL,
                            Severity.HIGH,
                            Severity.MEDIUM,
                            Severity.LOW,
                            Severity.INFO,
                        ].index(r.severity),
                    )

                    for result in sorted_results:
                        severity_badge = self._get_severity_badge(result.severity)
                        # Get the first failure location for display
                        if result.failure_locations:
                            loc = result.failure_locations[0]
                            location = f"L{loc.line}" if loc.line else "File"
                            message = loc.message.replace("|", "\\|")  # Escape pipes
                        else:
                            location = "File"
                            message = "No specific location"

                        rule_id = result.rule_id or result.checker_name
                        output.append(
                            f"| {severity_badge} | `{rule_id}` | {message} | {location} |"
                        )

                    output.append("")

        # Recommendations
        output.append("## Recommendations")
        output.append(self._format_recommendations(kpi, results))
        output.append("")

        # Footer
        output.append("---")
        output.append(
            "*Report generated by [src-check](https://github.com/yourusername/src-check)*"
        )

        return "\n".join(output)

    def _format_kpi_summary(self, kpi: KpiScore) -> str:
        """Format KPI summary section."""
        lines = []

        # Overall score with visual grade
        grade = self._get_grade(kpi.overall_score)
        lines.append(f"**Overall Score**: {kpi.overall_score:.1f}/100 {grade}")
        lines.append("")

        # Category breakdown
        if kpi.category_scores:
            lines.append("### Category Scores")
            lines.append("")
            lines.append("| Category | Score | Grade |")
            lines.append("|----------|-------|-------|")

            for category, score in sorted(kpi.category_scores.items()):
                grade = self._get_grade(score)
                lines.append(f"| {category.title()} | {score:.1f} | {grade} |")

        return "\n".join(lines)

    def _format_statistics(self, results: Dict[str, List[CheckResult]]) -> str:
        """Format statistics section."""
        total_files = len(results) if results else 0
        files_with_issues = len([f for f, r in results.items() if r])
        total_issues = sum(len(r) for r in results.values())

        # Count by severity
        severity_counts: Dict[Severity, int] = defaultdict(int)
        for file_results in results.values():
            for result in file_results:
                severity_counts[result.severity] += 1

        lines = []
        lines.append("| Metric | Value |")
        lines.append("|--------|-------|")
        lines.append(f"| Files Analyzed | {total_files} |")
        lines.append(f"| Files with Issues | {files_with_issues} |")
        lines.append(f"| Total Issues | {total_issues} |")

        return "\n".join(lines)

    def _format_issues_by_severity(self, results: Dict[str, List[CheckResult]]) -> str:
        """Format issues by severity breakdown."""
        severity_counts: Dict[Severity, int] = defaultdict(int)
        for file_results in results.values():
            for result in file_results:
                severity_counts[result.severity] += 1

        lines = []
        lines.append("| Severity | Count | Percentage |")
        lines.append("|----------|-------|------------|")

        total = sum(severity_counts.values())

        for severity in [
            Severity.CRITICAL,
            Severity.HIGH,
            Severity.MEDIUM,
            Severity.LOW,
            Severity.INFO,
        ]:
            count = severity_counts.get(severity, 0)
            percentage = (count / total * 100) if total > 0 else 0
            badge = self._get_severity_badge(severity)

            lines.append(f"| {badge} {severity.value} | {count} | {percentage:.1f}% |")

        return "\n".join(lines)

    def _format_recommendations(
        self, kpi: KpiScore, results: Dict[str, List[CheckResult]]
    ) -> str:
        """Generate recommendations based on results."""
        recommendations = []

        if kpi.critical_issues > 0:
            recommendations.append(
                "ğŸš¨ **Priority 1**: Fix all critical security issues immediately"
            )

        if kpi.high_issues > 0:
            recommendations.append(
                "âš ï¸ **Priority 2**: Address high-severity issues before deployment"
            )

        if kpi.overall_score < 70:
            recommendations.append(
                "ğŸ“ˆ **Quality**: Consider refactoring to improve code quality"
            )

        if (
            "test_quality" in kpi.category_scores
            and kpi.category_scores["test_quality"] < 60
        ):
            recommendations.append("ğŸ§ª **Testing**: Increase test coverage and quality")

        if not recommendations:
            recommendations.append(
                "âœ… **Great job!** Keep maintaining high code quality standards"
            )

        return "\n".join(f"- {rec}" for rec in recommendations)

    def _get_severity_badge(self, severity: Severity) -> str:
        """Get markdown badge for severity level."""
        badges = {
            Severity.CRITICAL: "ğŸ”´",
            Severity.HIGH: "ğŸŸ ",
            Severity.MEDIUM: "ğŸŸ¡",
            Severity.LOW: "ğŸ”µ",
            Severity.INFO: "â„¹ï¸",
        }
        return badges.get(severity, "")

    def _get_grade(self, score: float) -> str:
        """Get letter grade for score."""
        if score >= 90:
            return "ğŸŸ¢ A"
        elif score >= 80:
            return "ğŸŸ¢ B"
        elif score >= 70:
            return "ğŸŸ¡ C"
        elif score >= 60:
            return "ğŸŸ  D"
        else:
            return "ğŸ”´ F"
